% !TEX root = ../CedricDe Schepper2023_Thesis.tex

\section{Related Work}\label{sec:related-work}

This section details different types of algorithms researched to solve the timetabling problem. Additionally, it will also go over several benchmarks used to compare these algorithms.
%TODO expand on this


% \begin{description}
%     \item [Integer Programming] Integer Programming tries to solve an optimisation by minimising or maximising the problem's objective function. Fundamentally, some or all required variables are constrained to integers. Since integer programming makes use of an exhaustive search process, the search space must be reduced as much as possible to reduce the run time.
%     \item [Simulated Annealing] Simulated annealing\cite{kirkpatrick1983} makes use of a temperature variable which describes the level of randomness present in the acceptance of a new solution. After generating an initial solution, newly obtained solutions are accepted based on the change in objective function and current temperature. Over time the temperature cools down which reduces the amount of randomness.
%     \item [Adaptive Large Neighbourhood Search] Adaptive large neighbourhood search (ALNS) \cite{ropke2006} works by generating new solutions by constantly making changes to the current solution in order to explore the neighbourhood space. These changes are obtained by removing part of the variables and then reintroducing new values in order to generate neighbours. ALNS is considered adaptive since it keeps track of the performance of certain operations and adjusts its parameters accordingly. The use of ALNS for exam timetabling so far has been limited.
%     \item [Genetic Algorithms] Genetic algorithms (GA) \cite{Holland1975} are based on the process of natural selection witnessed in nature. They work by generating an initial set or population of possible solutions. Iteratively, a new population will be formed by selecting the fittest (best) solutions and combining two solutions to create a new generation of solutions.
%     \item [Particle Swarm Optimisation] Particle swarm optimisation (PSO) \cite{kennedy1995} is derived from the behaviour by collective species as seen in fish schools and bird flocks. A swarm of particles (see fish or bird), representing solutions, moves through the search space at a certain speed and direction.
%     \item [Honey-Bee Mating Optimisation] Honey-bee mating optimisation algorithms (HBMO) \cite{abbas2001} are based on the mating of honey-bees as witnessed in nature. During the mating procedure, the queen representing the current best solution is able to mate with other bees in order to produce new solutions.
%     \item [Great Deluge] Great deluge algorithms (GD) \cite{dueck1993} are based on the principle where an increasing water level is used to represent the allowed threshold. Only a solution that is superior in comparison with that threshold is accepted.
%     \item [Hyper-heuristics] Hyper-heuristics\cite{cowling2001} are designed to be problem-independent meaning no domain expertise and customisation is needed to be successfully applied to different problems. These heuristics utilise the heuristic the most optimal for the given problem.
% \end{description}
Several classes for optimisation methods exists, all with their own unique characteristics. Algorithms from the following classes are covered in this section:
\begin{description}
\item [Single Solution-based Meta-heuristics]

Single Solution-based Meta-heuristics are also commonly referred to as \acrfull{local} methods \cite{lin1973}. These heuristics first generate an initial solution. Afterwards, small changes are continuously applied to the solution using a specific strategy in order to traverse the search space. 

They can often be divided into either one-stage or two-stage algorithms \cite{lewis2008}. One-stage methods attempt to satisfy both the hard and soft constraints during the same stage. Two-stage approaches initially only take the hard constraints into account in order to generate a feasible solution. Afterwards, the second phase attempts to optimise the solution by adding the soft constraints. Since \acrshort{local} methods only accept a solution when its better than the previous one, encountering a worse solution blocks it from progressing. This means that \acrshort{local} requires strategies in order to escape local optima to keep improving the solution. 

% discuss the many parameters?


\item [Population-based Meta-heuristics]

Instead of applying meta-heuristic on a single solution, Population-based meta-heuristics maintain a set of solutions, called a population. Every iteration, a new population is generated by applying meta-heuristics. These methods offer the advantage over single solution-based methods that multiple solutions are presented during the final iteration. Another difference is that they prioritise exploration of the search space while single solution-based methods focus more in exploitation of their solution  \cite{kohshori2012}. However, this exploration does come at the cost of an increase in run time due to a larger amount of operations applied at each iteration.

\item [Exact Methods] 

Exact methods constrain the problem by defining a linear objective function and force some or all parameters to be integers. Since these methods make use of an exhaustive search process, the search space must be reduced as much as possible to reduce the run time. Unlike heuristics, exact methods can provide upper and lower bounds of the objective function and thus provide proof of optimality.

Fundamentally, some or all required variables are constrained to integers. 

\item [Hyper-heuristics]

Hyper-heuristics\cite{cowling2001} \cite{burke2013} are designed to be problem-independent meaning no domain expertise and customisation is needed to be successfully applied to different problems. They utilise the heuristic the most optimal for the given problem.

\end{description}

\subsection{Standardised data sets and benchmarks}

Even though the timetabling problem has been tackled in many research papers, Ceschia et al.\cite{ceschia2022} state that many of the initial benchmarks are not relevant anymore. They observe that many papers do not provide the data, source code or solutions used. This makes it impossible to confirm the presented results. Additionally, many of the problems researched are unique to specific institutions, reducing the amount of relevant observations that can be made from the results. However, effort has been put into standardising the timetabling problems into data sets that can be used to accurately compare different heuristics. The agreement regarding the need for benchmarks dates back to the first \acrfull{patat} in 1995 \cite{cumming1995}. Most of the current benchmarks available come from competitions like the \acrfull{itc}.

An early formulation for university exam timetabling was done by Carter et al. \cite{carter1996}. They initially introduced 13 exam timetabling data sets for several institutions, commonly referred to as the Toronto or Carter benchmarks. Additional instances have been made available over time \cite{bellio2021}. The data behind this format is implemented as a binary enrolment matrix, showing for each exam and student whether the student is enrolled for that exam. The objective function to compare solutions for this benchmark is based on the distance between exams and the amount of common students. The penalty for two exams with $k$ common students at a distance of $i$ periods was calculated as $k*w_{i}$. The values for $w_1$, $w_2$, $w_3$, $w_4$, and $w_5$ were set as $16$, $8$, $4$, $2$, and $1$, respectively. While this benchmark is still being used to compare heuristics, the simplification of several common constraints means that it less suitable to apply on real-world scenarios. For example, the benchmark is considered to be uncapacitated. This means that exam rooms are not taken into account when generating timetables. Since constraint 2 determines room capacity to be nonnegotiable in our use case, our timetabling problem does not fit in this format.

A later examination timetabling formulation was proposed for ITC-2007 by McCollum et al. \cite{mccollum2007}. This formulation is more advanced than the one proposed by Carter et al., taking more constraints into account. New constraints include the addition of exam rooms and more strict penalties related to the distance of scheduled exams. Initially, a data set of 12 instances was released for the competition but more real-world instances have been translated to the format over time \cite{parkes2010}, as well as the implementation of a generator to create artificial instances \cite{battistutta2017}.

Other common benchmarks focus on either the high school or university course scheduling problem. For example, Post et al. \cite{post2012} were the first to propose a standardised format for  high school timetabling. They developed XHSTT, an XML format to be used in solution benchmarks. Several data sets have been made available at \url{https://www.utwente.nl/en/eemcs/dmmp/hstt/}.
Additionally, this format has been used as the target for the third International Timetabling Competition in 2011. Unfortunately, university exam timetabling problems do not allow to be converted into course timetabling formats due to differences in constraints and schedule characteristics. Other examples include the \acrfull{cb-ctt} \cite{gaspero2007} and \acrfull{pe-ctt} \cite{lewis2007} formats, both used for ITC-2007.

These problem formulations provide valuable contributions in standardising the timetabling research, allowing for easier comparison between algorithms and checking of solutions. However, the uniqueness of the use cease for the University of Antwerp makes using these benchmarks infeasible. This makes it possible to only compare the quality of generated solutions against the ones manually generated.

\subsection{Single Solution-based Meta-heuristics}

Single Solution-based Meta-heuristics or \acrlong{local} methods start from an initial solution. Generally, this solution is generated randomly or using a greedy algorithm, but other techniques can also be used. \acrshort{local} then starts exploring the search space by calculating the neighbourhood of its current solution and picking a neighbour as its new solution. Different versions of \acrlong{local} use their own technique for choosing the neighbour and when to stop the search. The objective function is used to estimate the quality of each solution, with \acrshort{local} attempting to miminise this objective.
\subsubsection{Tabu Search}

\acrfull{tabu} \cite{glover1993} is based on \acrfull{local} \cite{lin1973}, meaning it traverses the possible search space by performing local changes to the current solution. Since \acrshort{local} will only accept improving solutions, this traversal can end up being stuck in a local optimum. \acrshort{tabu} differs from \acrshort{local} by relaxing this rule and also accepting worsening solutions. This relaxation allows for more exploration and allows \acrshort{tabu} to escape local optima. Additionally, \acrshort{tabu} maintains a memory structure to avoid changes being reversed. The usage of short- to long-term memory is  based on the assumption that optimisation techniques must incorporate memory to qualify as intelligent and that a bad strategic choice is superior to a good random choice\cite{glover1999}. This memory structure is implemented by maintaining a tabu list which contains the x most recent changes performed. A change is thus considered ‘tabu’ if it is present within the tabu list.

Alvarez-Valdes et al. \cite{alvarez1997} proposes a two-phased \acrlong{tabu} in order to solve the university exam timetabling problem. During
the first phase, the emphasis is on satisfying the hard constraints. More specifically, they attempt to reduce the amount of occurrences where a student has two exams on the same day. Optimally, this initialisation phase would return a solution that is already feasible. The second phase can be considered an optimisation phase, which tries to satisfy the soft constraints as much as possible and thus attempt to spread the exams as best as possible. They used this algorithm on real-world data sets of the University of Valencia, and compared it with the manually designed exam schedules. They conclude that the generated schedules are superior for all data sets.

Di Gaspero and Schaerf \cite{gaspero2001} adapt the original \acrshort{tabu} method by proposing changes to the tabu list and stopping criterion. Instead of keeping a fixed tabu list size, each move is assigned a number of iterations that the move is considered tabu. Additionally, the algorithm will terminate after a fixed amount of iterations without improvement. When comparing their results with the Carter benchmarks, they note that \acrlong{tabu} provides comparable performance with the benchmarks.

Chu and Fang \cite{Chu2000} made a comparison between using \acrlong{ga} versus \acrlong{tabu} to obtain time tables. For all of their different experiments, the \acrfull{tabu} implementation was able to outperform their \acrshort{ga} version, both on the quality of the solution and the computational time needed to converge. However, a redeeming quality of \acrlong{ga} is that they are able to produce several near optimal solutions in one go while \acrlong{tabu} implementations are limited to a single solution. 

Colorni et al. \cite{colorni1999} apply \acrlong{tabu}, \acrlong{sa}, and \acrlong{ga} on the high school timetabling problem for an Italian high school. They conclude that \acrshort{tabu} outperforms both competitors in generating quality timetables for their use case.



\subsubsection{Simulated Annealing}

Aycan and Ayav \cite{aycan2009} apply \acrfull{sa} \cite{kirkpatrick1983} to generate optimal solutions. In order to create a initial solution as optimal as possible, constraint satisfaction methods are used to create a solution satisfying all hard constraints. During the simulated annealing phase, a new solution is found by randomly swapping two variables. The cost of the new solution is then calculated using the objective function. Whenever the new objective is lower than the objective of the previous solution, the algorithm will keep the new solution. In the case of a higher objective, the temperature will determine based on the difference between the two costs whether to keep the new solution or discard it. The possibility of accepting worsening solutions allows the algorithm to avoid being stuck in local minima. Over time the temperature will reduce based on the cooling schedule. Practically, the allowed difference in cost for worsening solutions in order to still be accepted will decrease. As the temperature decreases, the focus switches from exploring to exploiting the search space. This will allow the algorithm to eventually converge towards a local or global minimum. The performance of simulated annealing is determined by the choice of initial solution, the objective function, and cooling schedule. 

The objective function accounts for the impact of both hard as well as soft constraints. Every constraint is assigned its own penalty function including a constraint weight. The cooling schedule proposed makes use of geometric schedule. That means that the temperature will decrease by a constant factor during every step of the algorithm. The choice for the initial temperature and cool-down factor will determine the share of the search space visited. 

While geometric cooling is very simple to implement, it has some shortcomings. Since the temperature is calculated by a deterministic schedule, it mostly depends on the variables chosen by the user. Additionally, this schedule also does not take into account the progress made by the algorithm. Alternatively, more complex adaptive cooling schedules will decrease, or even increase, the temperature based on the rate of acceptance for new solutions. While Aycan and Ayav conclude that this method succeeds in satisfying the hard constraint in order to find a feasible solution, implementing a hybrid version or adding reheating to the cooling schedule might obtain higher quality results.
% TODO data set

A more complex cooling schedule can be seen in the \acrfull{sar} algorithm by Leng Goh et al.\cite{Goh2017}. They propose a two stage hybrid timetabling algorithm where the first stage uses \acrlong{tabu} to generate a feasible solution. If such a solution is found, the second stage attempts to improve on it by using \acrshort{sar}. Instead of using geometric cooling, reheating or increasing the temperature is possible. This is based on the assumption that whenever the objective is high, the focus should be on exploration and accordingly whenever the objective is low, exploitation is prioritised. Whenever the search is estimated to be stuck in a local optima, the temperature will be reheated until it manages to escape. 

This estimate is made by checking the difference between the best and current objective. If the change in objective is under a certain threshold for a pre-determined amount of iterations, the search is considered to be stuck and reheating will occur. This cooling and reheating repeats itself until an optimal solution has been found or a step limit is reached. An additional benefit to reheating compared to a geometric schedule is that no fine-tuning of variables is needed when extending the run time. Figure \ref{fig:SAR} showcases the effect that enabling reheating has on the temperature, with its value increasing whenever it gets stuck in a local optimum. As a consequence, the search is allowed to explore more, resulting in a higher amount of variation of the objective. In this case, the reheating allowed the search to discover a more optimal solution.
% TODO data set

\begin{figure}[h]
  \centering
  \subfloat[\acrshort{sar} with reheating disabled]{\includegraphics[width=0.5\textwidth]{images/related_works/SA/SAR_disabled.png}}
  \hfill
  \subfloat[\acrshort{sar} with reheating enabled]{\includegraphics[width=0.5\textwidth]{images/related_works/SA/SAR_enabled.png}}
  \caption{Effect of reheating on the temperate and objective for \acrlong{sa} as discovered by Leng Goh et al.\cite{Goh2017}}
  \label{fig:SAR}
\end{figure}





\subsubsection{Adaptive Large Neighbourhood Search}

\acrshort{alns} \cite{ropke2006} works by generating new solutions by constantly making changes to the current solution in order to explore the neighbourhood space. These changes are obtained by removing part of the variables and then reintroducing new values in order to generate neighbours. ALNS is considered adaptive since it keeps track of the performance of certain operations and adjusts its parameters accordingly. 

S{\o}rensen and Stidsen \cite{sorensen2012} propose a version of \acrshort{alns}, building on the more general \acrfull{lns} algorithm. \acrshort{lns} works by creating new solutions by applying a "destroy" and "repair" operation. Every step a destroy operation will remove a set of variables from the problem, before reintroducing new variables in order to create new solutions. By changing multiple variables, \acrshort{lns} is able to escape local minima. In the proposed \acrshort{alns} extension however, the single destroy and repair operations are replaced by multiple operations, chosen at random during execution. This changes the original deterministic model into a stochastic version, introducing randomness. Additionally an adaptive layer analyses the impact of each operator and increases the probability of operators having a positive impact on the objective function.

\subsubsection{Great Deluge}

Dueck \cite{dueck1993} first proposed a \acrfull{gd} algorithm as alternative to \acrlong{sa}. It is built on the principle that the search space is limited by an ever changing water level. Newly generated solutions are only considered whenever they are superior compared to the objective threshold level that is represented by the water level. New solutions are found by performing low-level heuristics such as swapping two exams. While Dueck makes use of a simple linear function to determine the water level, different functions can be applied instead. While \acrlong{sa} accepts worsening solutions based on a probabilistic value, \acrshort{gd} has a hard cut-off point for accepting solutions. 

% something about the 
Burke et al. \cite{burke2004GD} are the first to apply an algorithm based on \acrlong{gd} to the exam timetabling problem. Their reason for using \acrshort{gd} is to be able to control the exact run time of the search while still allow the search to converge. While this could be done with the \acrlong{sa} algorithm for example, determining the exact cooling rate for a correct execution time is often too complex. Instead they propose a \acrshort{gd} implementation that they call a degraded ceiling algorithm. Instead of a changing water level, they describe a lowering ceiling with the ceiling representing the upper boundary of the objective function allowed. By slowly moving the ceiling down, the run time before convergence can be accurately determined. This is valuable for university administrators responsible for creating exam timetables since they could let the search run overnight or during the weekend.

By slowly lowering the ceiling, exploration to worsening solutions is feasible as long as the ceiling level has not cut off certain sections of the search space. As the ceiling lowers, the search space becomes tighter and priority shifts to exploitation. This continues until no further improvement is feasible and the stopping criterion is met. They conclude that this degraded ceiling implementation is not only superior to a time limited simulation annealing version, but that running this algorithm for long periods can produce extremely good results. Based on their experiments, degraded ceiling can outperform most algorithms whenever a long run time is feasible.

Kahar and Kendall \cite{kahar2015} propose an modified \acrlong{gd} algorithm where the water level or decay rate is dynamically changed. Whenever no improvements are found, the change in water level can be reversed in order to allow more exploration. Based on their experiments using data from Universiti Malaysia Pahang, the modified \acrshort{gd} algorithm outperforms both the university's proprietary software and the original algorithm by Dueck \cite{dueck1993}. Lnasya Syafitrie and Komarudin \cite{Lnasya2022} implemented their own version based on this modified algorithm, with the main change being a slower rate at which the water rises. They find that their version outperforms that of Kahar and Kendall.

%Section 4 + modified algo (good paper)
%Kahar and kendall
%https://www.tandfonline.com/doi/abs/10.1057/jors.2012.169?journalCode=tjor20
%https://sci-hub.st/https://doi.org/10.1057/jors.2012.169

McMullan \cite{mcmullan2007} has implemented the \acrlong{gd} algorithm with the addition of a reheating step, similar to the reheating used for \acrlong{sar} \cite{Goh2017}. This better allows the search to escape local optima. While the general \acrshort{gd} algorithm would terminate after observing no improvement for an amount of time steps, the extended will apply a one-time reheating, reducing the water level again. this allows certain worsening solutions to be accepted again resulting in a larger possible search space. Afterwards the decay rate is increased compared to the initial rate. Experiments using small, medium, and large benchmark data sets show that the extended GD algorithm outperforms other implementations such as \acrlong{local} and ant algorithms on the medium data sets. For the small and large data sets, no notable difference is noted.


\subsection{Population-based Meta-heuristics}
\subsubsection{Genetic Algorithms}

\acrfull{ga} \cite{Holland1975} are based on the process of natural selection witnessed in nature. It generally consists of several base steps before reaching a final solution. First, the algorithm creates an initial population consisting of feasible solutions. An iterative approach is then taken in order to evolve this population into new generations. For every generation, the fitness of each individual in the population is determined and the 'fittest' individuals are chosen as parents for the new generation. In order to obtain new offspring, genetic operators such as crossover and mutation are applied. Crossover works by combining information of parent solutions into a new offspring. This can be done by swapping exam assignments across the parents. Mutation on the other hand randomly changes assignments in order to create new offspring. This is done in order to maintain randomness, allowing \acrshort{ga} to escape local minima. The flow of \acrlong{ga} can be seen in Figure \ref{fig:GA}.

\begin{figure}[h]
	\centering
	\includegraphics[width=0.40\textwidth]{images/related_works/GA/GA.png} 
	\caption{\acrlong{ga} flow}
	\label{fig:GA}
\end{figure}

The paper submitted by Pillay and Banzhaf \cite{pillay2010} showcases a two-phased approach to create feasible timetables. Both phases utilise a \acrshort{ga} implementation in order to come to a solution, with the first phase focusing on producing a timetable that does not violate any hard constraints. The second phase later attempts to optimise the objective of the soft constraints. Up until 2007, most papers applying \acrshort{ga} used data sets specific to a particular institution. This algorithm is tested on the Carter benchmarks \cite{carter1996}, allowing its performance to be compared to different approaches.

During the first phase, domain specific heuristics are used instead of random operations in order to create the initial population. While these heuristics require domain knowledge, the quality of the initial population should be superior. In order to determine the next exam to be assigned, the obtained heuristics make use of the number of conflicts, the number of students enrolled per exam, or the number of students with conflicts. These heuristics were then compared to random and best-slot scheduling. It was found that using heuristics succeeded in lowering the soft constraints objective compared to other scheduling methods. For the iterative steps, the fitness function is described as the amount of conflicts per timetable. In order to select the parents with which to generate the new generation, tournament selection is applied. Here, a determined amount of individuals are randomly chosen from the population to be compared against each other. The individual having the lowest objective ends up being selected. This process is repeated until all parents have been selected. When creating new offspring, both mutation and crossover operators were considered. During mutation, a random amount of conflicting examinations are rescheduled. Moreover, crossover operations that randomly swap time slots between two parents were tested. This requires an additional repair mechanism to remove duplicate examinations and schedule missing examinations. However, they note that the crossover operations applied did not positively impact the quality of the solutions. For the final implementation, only the mutation operation on single parents is used to create offspring.

The second phase focuses on minimising the objective of the soft constraints in order the generate a more optimal timetable. While very similar to the first phase,  mutation operations are now continuously applied until an offspring superior to the parent is found or until a certain amount of iterations has been reached. The performance of this genetic algorithm was eventually compared to other studies using the same benchmark including \acrlong{tabu} and l\acrlong{lns}. While no optimal solutions were found for any of the data sets, equal or improved solutions were obtained compared to alternative methods. They conclude that their implementation equals or even outperforms other evolutionary algorithms on the Carter benchmarks.

\subsubsection{Particle Swarm Optimisation}

\acrfull{pso} \cite{kennedy1995} is derived from the behaviour by collective species as seen in fish schools and bird flocks. A swarm of particles (see fish or bird), representing solutions, moves through the search space at a certain speed and direction.
% TODO: expand on this?

Chen and Shih \cite{Chen2013} discuss a \acrlong{pso} implementation combined with \acrlong{local}. During \acrshort{pso}, a swarm of particles, corresponding to different timetables, moves through the available search space. During every iteration, each particle will remember its best encountered position and share its information with the rest of the swarm. The particles will then adjust their velocity and direction on both their personal and global best. The velocity can be seen as the magnitude of the allowed change per time step. Additionally, a local search iteration is applied to explore the surrounding space for a better solution. In order to avoid particles being trapped in a local optimum, a disturbance operation is introduced \cite{tsai2010}. This operation forces particles to move towards unexpected directions, that aren't based on previous experience. Doing this, the amount of exploration is increased.
% TODO data set

Tassopoulos and Beligiannis \cite{Tassopoulos2012} builds on the general \acrlong{pso} algorithm. Initially, they start with a high amount of 150 particles. Whenever the fitness value of a produced particle exceeds a certain tolerance value, this particle is set to inactive and will not be used in further steps. This tolerance value is calculated during each step in order to deactivate weak particles at the start but make it harder for particles to reach that threshold down the line. When the amount of particles is reduced to 30, this procedure stops. The reasoning behind starting with a large amount of particles is to make it possible to explore a wider search space while keeping the execution time down by reducing the particles over time. Similar to Chen and Shih's approach \cite{Chen2013} a \acrlong{local} algorithm is used to minimise one of the soft constraints. Results show that it outperforms the \acrfull{ga} implementation that their \acrshort{pso} version was tested against.
% TODO data set
\subsubsection{Honey-Bee Mating Optimisation}

\acrfull{hbmo} \cite{abbas2001} are based on the mating of honey-bees as witnessed in nature. During the mating procedure, the queen representing the current best solution is able to mate with other bees in order to produce new solutions. Since specific terms used in the natural mating process are used when describing the optimisation algorithm, Table \ref{tab:hbmo} provides translation of the analogy. \acrshort{hbmo} follows the natural process when the queen leaves the hive on a mating flight. Here she maintains a certain speed and direction, creating the possibility of drones to mate with her. After mating with a drone, its genetic information is stored within the queen to be used in the breeding phase. After each mating, the queen will change her energy and speed. As soon as the queen reaches a certain energy threshold or reaches a mating limit, she will return to the hive. Upon return, the queen will randomly select genetic information obtained and perform a crossover step to create a new brood. Every brood is fed by a worker in order to improve the obtained solution. After every brood is improved, the fittest brood is compared to the queen. If the brood corresponds to a superior solution, the queen is replaced by the brood. Both the queen and the other broods are killed and a new mating flight will commence. 

Sabar et al. \cite{Sabar2009} are the first to propose the use of \acrlong{hbmo} in order to solve the exam timetabling problem. The proposed variant on the original algorithm \cite{abbas2001} attempts to solve \acrshort{hbmo}'s weakness of suffering from early convergence. Originally, the drones, that are used to mate with the queen, are never replaced which reduces the amount of variation. This is solved by replacing the drones that were successful in mating with the newly created broods. Additionally, after crossover, the heuristic applied by the worker is based on \acrlong{local} in order to optimise the brood as much as possible.

While \acrshort{hbmo} is very similar to other population based methods such as genetic algorithms, two clear differences can be noted. First, \acrshort{hbmo} maintains the queen as one of the two 'parents' used during crossover. Since the queen is considered as the current best solution, this is meant to improve obtained solutions. Secondly, the \acrlong{local} applied by the worker can be considered an exploitation phase which is not present in \acrlong{ga}. Finally, Sabar et al. conclude that the proposed \acrshort{hbmo} alternative manages to create comparable or superior solutions compared against other population-based methods.

\begin{table}[h]
	\caption{Analogy between the natural mating process and the \acrshort{hbmo} algorithm}
	\label{tab:hbmo}
	\centering
	\begin{tabular}{l c c }
		\hline
		\textbf{Natural honey bee}  & \textbf{Artificial honey bee} \\ \hline
		Queen & Current best solution \\
		Drones & Possible solutions \\
	    Broods & Newly generated solutions \\
            Worker & Heuristic search \\
            Mating or Breeding & Crossover \\ \hline
	\end{tabular}
\end{table}

% TODO data set

\subsection{Exact Methods}
\subsubsection{Integer Programming}

Kristiansen et al. \cite{kristiansen2015} describe a \acrfull{mip} model designed to solve XHSTT timetabling data sets. The XHSTT format was formulated to standardise timetabling data sets in order to compare heuristics. The proposed model makes use of two stages. During the first stage, a simplified \acrshort{mip} model is generated taking only the hard constraints of the problem into account. This stage is ran until a specified amount of time has passed or until the model has been solved to optimality. The benefit of using integer programming here is that \acrshort{mip} models can issue 'certificates of optimality, indicating that an optimal solution has been reached. This differs from heuristic methods where a model cannot guarantee that an optimal solution has been found unless the objective function is brought to 0. With \acrshort{mip} models, one can determine whether the cost generated by the hard constraints is the most optimal solution feasible. This allows a clear cut off point for the model to stop focusing on the hard constraints solely. 

If a certificate of optimality can be generated, the second stage is executed. Otherwise, the algorithm ends. Before solving the model in stage 2, the soft constraints are added again. Additionally, an extra constraint is added which keeps the optimal value of the cost generated by the hard constraints. The second stage ends after the remaining time after stage 1 has passed. The proposed model was not only successful in creating 2 new solutions to XHSTT data sets, it was also able to prove optimality of previously found solutions. Additionally, it could also provide the lower bounds for several other data sets and improve the best solution found so far. These lower bounds are crucial in order to compare the quality of solutions that have not reached optimality.
% TODO data set

Al-hawari et al. \cite{hawari2017} attempts to solve the university exam timetabling problem by splitting the problem into three smaller sub-problems in order to significantly decrease the amount of variables required in the formulas used and thus reduce the processing power and storage capacity needed. Additionally, the simplification of the formulas also improves the explainability of the model, making it easier to understand. The initial problem is split into 3 problems, each sub-problem continuing on the solution provided by the previous phase. Phase one and two will use a  graph colouring \acrfull{ip} model to generate a feasible solution. Graph colouring works by assigning colours to the vertices while avoiding that two vertices connected by an edge are assigned the same colour. These vertices are called adjacent. Additionally, graph colouring will attempt to use the least amount of colours possible to generate a feasible solutions.

The first phase starts by assigning time slots to the different exams. Different from stated in the problem definition, Al-hawari et al. consider a time slot to be a moment in time when exams are being held. For example, during an exam period of 20 days with two exam moments a day, there would be 40 time slots available for exams to be planned. Initially, these time slots are solely an exam moment and do not include a day yet. During the first phase, exams are seen as the vertices with two vertices being connected by an edge if a student is enrolled in both exams. The time slots act as colours and are assigned to the vertices. Every feasible solution produced by this phase will satisfy the hard constraint that a student can not have more than one exam at the same time. Phase two builds upon this solution by assigning days to the time slots, meaning that the time slots are now considered vertices and the different days colours. Again, vertices are adjacent if the exams assigned to the time slots share mutual students. The new solution will have added the extra constraint that a student can't have two exams on the same day. Lastly, the third stage will assign all exams to rooms, keeping into account the exam enrolment and room capacity. The final solution, if feasible, will satisfy all hard constraints. An important remark to note is that no soft constraints were introduced for creating an improved exam distribution. As a result, a feasible solution will only make sure that a student has no exams on two following days or on the same day.
% TODO data set


\subsection{Hyper-heuristics}

While many optimisation methods have proven successful in generating optimal solutions, many of these methods are designed for a single problem and require domain-specific knowledge to be efficient. Hyper-heuristics attempt to solve this problem by providing a problem-independent solution which allows different methods to be used across problems. They can be considered either selective or generative. Selective hyper-heuristics choose from a predefined set of heuristics depending on the problem encountered, while generative hyper-heuristics procure new heuristics by combining multiple heuristics.

Kheiri and Keedwell \cite{kheiri2017} focus on the selection hyper-heuristics to solve the high school timetabling problem. Every iteration in the solution process, consists of two steps. First, low-level heuristics are applied. These heuristic apply basic operations to create new solutions. Secondly, a move acceptance method will determine whether the keep or discard the new solution. In their study, a set of 15 low-level heuristics are employed including randomly rescheduling or unscheduling an exam, shuffling the time slots of several exams, changing the room of an exam,.... For the move acceptance method, several methods such as Hill Climbing, \acrlong{sa} and, \acrlong{gd} are compared. The choice of acceptance method will determine when a new solution is accepted. In hill climbing, a solution will only be accepted if its better compared to the previous solution. On the other hand, in \acrlong{sa}, worse solutions can be considered due to the probability determined by the temperature.

The hyper-heuristic proposed by Kheiri and Keedwell proposes a sequence-based selection where each time a sequence of heuristics is applied instead of a single heuristic. Experiment results show that these sequences outperform single applications of heuristics and that the selection of the low-level heuristics is more important than the move acceptance method used. They finally conclude that the proposed method provides solutions superior to those of previous popular methods.

Kendall and Mohd Hussin \cite{kendall2004} describe a hyper-heuristic where the order of the low-level heuristics applied to the current solution is determined by a \acrlong{tabu} implementation. At each step of the search, the heuristic with the best performance, if not tabu, is chosen to explore its own search space. The heuristics chosen then become tabu, which means that they will not be considered in the next iterations. Because of this, the search space of other low-level heuristics that might perform worse will also be explored. The size of the tabu list becomes a variable to be optimised for each problem instance. The same set of 13 low-level heuristics proposed during one of their previous experiments was reused \cite{kendall2005}. Kendall and Mohd Hussin conclude that the hyper-heuristic is able to find solutions that are 80\% better compared to manual generated solutions based on their objective function.



